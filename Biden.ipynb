{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages if not already installed\n",
    "#pip install s3fs\n",
    "#pip install nltk\n",
    "#pip install wordcloud\n",
    "#pip install seaborn\n",
    "\n",
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load S3 Bucket into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deolg\\AppData\\Local\\Temp\\ipykernel_12676\\2768635924.py:2: DtypeWarning: Columns (1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  biden_df = pd.read_csv('s3://bidentweetscsv/hashtag_joebiden.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>collected_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:01</td>\n",
       "      <td>1.316529221557252e+18</td>\n",
       "      <td>#Elecciones2020 | En #Florida: #JoeBiden dice ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>360666534.0</td>\n",
       "      <td>El Sol Latino News</td>\n",
       "      <td>elsollatinonews</td>\n",
       "      <td>üåê Noticias de inter√©s para latinos de la costa...</td>\n",
       "      <td>...</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>Philadelphia, PA / Miami, FL</td>\n",
       "      <td>25.77427</td>\n",
       "      <td>-80.19366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>2020-10-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>1.31652929585929e+18</td>\n",
       "      <td>#HunterBiden #HunterBidenEmails #JoeBiden #Joe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>809904438.0</td>\n",
       "      <td>Cheri A. üá∫üá∏</td>\n",
       "      <td>Biloximeemaw</td>\n",
       "      <td>Locked and loaded Meemaw. Love God, my family ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6628.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-21 00:00:00.517827283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:20</td>\n",
       "      <td>1.3165293050069524e+18</td>\n",
       "      <td>@IslandGirlPRV @BradBeauregardJ @MeidasTouch T...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>3494182277.0</td>\n",
       "      <td>Flag Waver</td>\n",
       "      <td>Flag_Wavers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>Golden Valley Arizona</td>\n",
       "      <td>46.304036</td>\n",
       "      <td>-109.171431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Montana</td>\n",
       "      <td>MT</td>\n",
       "      <td>2020-10-21 00:00:01.035654566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 00:00:21</td>\n",
       "      <td>1.3165293080815575e+18</td>\n",
       "      <td>@chrislongview Watching and setting dvr. Let‚Äôs...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>8.242596012018524e+17</td>\n",
       "      <td>Michelle Ferg</td>\n",
       "      <td>MichelleFerg4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-21 00:00:01.553481849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:22</td>\n",
       "      <td>1.316529312741253e+18</td>\n",
       "      <td>#censorship #HunterBiden #Biden #BidenEmails #...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.032806955356545e+18</td>\n",
       "      <td>the Gold State</td>\n",
       "      <td>theegoldstate</td>\n",
       "      <td>A Silicon Valley #independent #News #Media #St...</td>\n",
       "      <td>...</td>\n",
       "      <td>390.0</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>36.701463</td>\n",
       "      <td>-118.755997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-10-21 00:00:02.071309132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                tweet_id  \\\n",
       "0  2020-10-15 00:00:01   1.316529221557252e+18   \n",
       "1  2020-10-15 00:00:18    1.31652929585929e+18   \n",
       "2  2020-10-15 00:00:20  1.3165293050069524e+18   \n",
       "3  2020-10-15 00:00:21  1.3165293080815575e+18   \n",
       "4  2020-10-15 00:00:22   1.316529312741253e+18   \n",
       "\n",
       "                                               tweet likes  retweet_count  \\\n",
       "0  #Elecciones2020 | En #Florida: #JoeBiden dice ...   0.0            0.0   \n",
       "1  #HunterBiden #HunterBidenEmails #JoeBiden #Joe...   0.0            0.0   \n",
       "2  @IslandGirlPRV @BradBeauregardJ @MeidasTouch T...   0.0            0.0   \n",
       "3  @chrislongview Watching and setting dvr. Let‚Äôs...   0.0            0.0   \n",
       "4  #censorship #HunterBiden #Biden #BidenEmails #...   1.0            0.0   \n",
       "\n",
       "               source                user_id           user_name  \\\n",
       "0           TweetDeck            360666534.0  El Sol Latino News   \n",
       "1    Twitter for iPad            809904438.0         Cheri A. üá∫üá∏   \n",
       "2     Twitter Web App           3494182277.0          Flag Waver   \n",
       "3  Twitter for iPhone  8.242596012018524e+17       Michelle Ferg   \n",
       "4     Twitter Web App  1.032806955356545e+18      the Gold State   \n",
       "\n",
       "  user_screen_name                                   user_description  ...  \\\n",
       "0  elsollatinonews  üåê Noticias de inter√©s para latinos de la costa...  ...   \n",
       "1     Biloximeemaw  Locked and loaded Meemaw. Love God, my family ...  ...   \n",
       "2      Flag_Wavers                                                NaN  ...   \n",
       "3    MichelleFerg4                                                NaN  ...   \n",
       "4    theegoldstate  A Silicon Valley #independent #News #Media #St...  ...   \n",
       "\n",
       "  user_followers_count                 user_location        lat        long  \\\n",
       "0               1860.0  Philadelphia, PA / Miami, FL   25.77427   -80.19366   \n",
       "1               6628.0                           NaN        NaN         NaN   \n",
       "2               1536.0         Golden Valley Arizona  46.304036 -109.171431   \n",
       "3                 27.0                           NaN        NaN         NaN   \n",
       "4                390.0               California, USA  36.701463 -118.755997   \n",
       "\n",
       "  city                   country      continent       state state_code  \\\n",
       "0  NaN  United States of America  North America     Florida         FL   \n",
       "1  NaN                       NaN            NaN         NaN        NaN   \n",
       "2  NaN  United States of America  North America     Montana         MT   \n",
       "3  NaN                       NaN            NaN         NaN        NaN   \n",
       "4  NaN  United States of America  North America  California         CA   \n",
       "\n",
       "                    collected_at  \n",
       "0            2020-10-21 00:00:00  \n",
       "1  2020-10-21 00:00:00.517827283  \n",
       "2  2020-10-21 00:00:01.035654566  \n",
       "3  2020-10-21 00:00:01.553481849  \n",
       "4  2020-10-21 00:00:02.071309132  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from S3 to dataframe\n",
    "biden_df = pd.read_csv('s3://bidentweetscsv/hashtag_joebiden.csv')\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1059909 entries, 0 to 1059908\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   created_at            1059909 non-null  object \n",
      " 1   tweet_id              887173 non-null   object \n",
      " 2   tweet                 887173 non-null   object \n",
      " 3   likes                 887092 non-null   object \n",
      " 4   retweet_count         887073 non-null   float64\n",
      " 5   source                886360 non-null   object \n",
      " 6   user_id               887067 non-null   object \n",
      " 7   user_name             887048 non-null   object \n",
      " 8   user_screen_name      786660 non-null   object \n",
      " 9   user_description      704647 non-null   object \n",
      " 10  user_join_date        776784 non-null   object \n",
      " 11  user_followers_count  776885 non-null   object \n",
      " 12  user_location         543063 non-null   object \n",
      " 13  lat                   355284 non-null   object \n",
      " 14  long                  355284 non-null   object \n",
      " 15  city                  186869 non-null   object \n",
      " 16  country               353770 non-null   object \n",
      " 17  continent             353788 non-null   object \n",
      " 18  state                 260191 non-null   object \n",
      " 19  state_code            244603 non-null   object \n",
      " 20  collected_at          776777 non-null   object \n",
      "dtypes: float64(1), object(20)\n",
      "memory usage: 169.8+ MB\n"
     ]
    }
   ],
   "source": [
    "biden_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = biden_df.sum()\n",
    "print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "biden_df = biden_df.drop(columns=['tweet_id', 'source', 'user_id', 'user_name', 'user_screen_name', 'user_description', 'user_join_date', 'user_location', 'lat', 'long', 'city', 'continent', 'state_code', 'collected_at'])\n",
    "\n",
    "# Display Dataframe\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that are not from the United States of America\n",
    "biden_df = biden_df[biden_df['country'] == 'United States of America']\n",
    "\n",
    "# Display Dataframe\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "biden_df = biden_df.dropna()\n",
    "\n",
    "# Display Dataframe\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info on the dataframe\n",
    "biden_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'likes' and 'user_followers_count' to numeric\n",
    "biden_df['likes'] = pd.to_numeric(biden_df['likes'], errors='coerce')\n",
    "biden_df['user_followers_count'] = pd.to_numeric(biden_df['user_followers_count'], errors='coerce')\n",
    "\n",
    "# Convert 'created_at' to datetime\n",
    "biden_df['created_at'] = pd.to_datetime(biden_df['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm changes\n",
    "biden_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "import re\n",
    "\n",
    "def clean_tweet_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\S+', '', text)     # Remove mentions\n",
    "    text = re.sub(r'#\\S+', '', text)     # Remove hashtags\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) # Remove non-alphabetic characters\n",
    "    return text\n",
    "\n",
    "biden_df['cleaned_tweet'] = biden_df['tweet'].apply(clean_tweet_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'tweet' is an empty string\n",
    "biden_df = biden_df[biden_df['cleaned_tweet'].astype(str).str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dataframe\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NLTK library and download the VADER lexicon\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SentimentIntensityAnalyzer class from the NLTK library\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    score = sia.polarity_scores(text)\n",
    "    if score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the function to DataFrame\n",
    "biden_df['sentiment'] = biden_df['cleaned_tweet'].apply(get_vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dataframe\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "biden_df.to_csv('Resources/hashtag_joebiden_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign numerical values to sentiments (e.g., positive: 1, neutral: 0, negative: -1)\n",
    "sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "biden_df['sentiment_numeric'] = biden_df['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns for correlation\n",
    "columns_for_correlation = ['likes', 'retweet_count', 'user_followers_count', 'sentiment_numeric']\n",
    "correlation_matrix = biden_df[columns_for_correlation].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix for Sentiment and Engagement Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparing data for regression analysis\n",
    "X = biden_df[['likes', 'retweet_count', 'user_followers_count']]\n",
    "y = biden_df['sentiment_numeric']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate metrics\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Mean Absolute Error: {MAE}\")\n",
    "print(f\"Mean Squared Error: {MSE}\")\n",
    "print(f\"R-squared Score: {R2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " understand how the textual content of tweets reflects sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'cleaned_tweet' is feature column and 'sentiment' is the target\n",
    "X =biden_df['cleaned_tweet'] #Features (X)\n",
    "\n",
    "y =biden_df['sentiment_numeric'] #Target (y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with TF-IDF Vectorizer and Logistic Regression\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Moving to BERT with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize the model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example of tokenizing input for BERT\n",
    "def encode_examples(texts, labels, tokenizer, max_length=512, pad_to_max_length=True):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "\n",
    "    for text in texts:\n",
    "        bert_input = tokenizer.encode_plus(text,\n",
    "                                           add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                                           max_length=max_length,  # Max length to truncate/pad\n",
    "                                           pad_to_max_length=pad_to_max_length,  # Pad sentence to max length\n",
    "                                           return_attention_mask=True,  # Return attention mask\n",
    "                                           )\n",
    "        \n",
    "        input_ids.append(bert_input['input_ids'])\n",
    "        attention_masks.append(bert_input['attention_mask'])\n",
    "        token_type_ids.append(bert_input['token_type_ids'])\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_ids = tf.constant(input_ids)\n",
    "    attention_masks = tf.constant(attention_masks)\n",
    "    token_type_ids = tf.constant(token_type_ids)\n",
    "    labels = tf.keras.utils.to_categorical(labels, num_classes=3)  # Assuming 3 classes for sentiment\n",
    "\n",
    "    return input_ids, attention_masks, token_type_ids, labels\n",
    "\n",
    "# Preparing dataset\n",
    "# Assuming 'texts' is a list of tweets and 'labels' is a list of numerical sentiment labels\n",
    "input_ids, attention_masks, token_type_ids, labels = encode_examples(biden_df['cleaned_tweet'].tolist(), \n",
    "                                                                     biden_df['sentiment_numeric'].tolist(),\n",
    "                                                                     tokenizer)\n",
    "\n",
    "# Define the dataset using TensorFlow\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": input_ids, \n",
    "                                               \"attention_mask\": attention_masks, \n",
    "                                               \"token_type_ids\": token_type_ids}, \n",
    "                                              labels))\n",
    "\n",
    "# Splitting the dataset, training the model, and evaluation would follow here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the ImportError you're encountering and proceed with using TensorFlow for your sentiment analysis task, you'll need to adapt your code to use TensorFlow's version of BERT for sequence classification, which is TFBertForSequenceClassification. This adjustment is necessary since your environment currently supports TensorFlow, not PyTorch. Below is an example of how to adjust your code to use TensorFlow classes for loading and utilizing a BERT model for sequence classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of sentiment distribution\n",
    "sns.countplot(x='sentiment', data=biden_df)\n",
    "plt.title('Sentiment Distribution of Biden Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of actual vs predicted values\n",
    "plt.scatter(X_test['likes'], y_test, color='blue', label='Actual', alpha=0.5)\n",
    "plt.scatter(X_test['likes'], y_pred, color='red', label='Predicted', alpha=0.5)\n",
    "\n",
    "# Line of best fit\n",
    "m, b = np.polyfit(X_test['likes'], y_pred, 1)\n",
    "plt.plot(X_test['likes'], m*X_test['likes'] + b, color='green')\n",
    "\n",
    "plt.xlabel('Likes')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.title('Actual vs Predicted Sentiment Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Join all the tweets into a single string\n",
    "text = ' '.join(biden_df['cleaned_tweet'])  # Assuming 'cleaned_tweet' is your column name\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                      background_color ='white', \n",
    "                      min_font_size = 10).generate(text)\n",
    "\n",
    "# Plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dev] *",
   "language": "python",
   "name": "conda-env-.conda-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
